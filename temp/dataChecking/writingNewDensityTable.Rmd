---
title: "Testing New Densities"
author: "Tati Micheletti"
date: "7/16/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(tidyr)
```

## Why this file?  

Talking to Nicole and Alberto to understand where the data from Alberto's `Final_points_2010.csv` 
table come from in order to be able to predict correctly using the same abundances, I came across
a situation where Alberto used a file named `DDB_BCR_PROV_LCC_Apr4-2012.csv` while Nicole suggested 
that the right densities should come from a file named `Habitat_Association_by_jurisdiction(bamddb_Apr19-2012).csv`.

Therefore, I have analyzed the differences between the two datasets and concluded that I should re-run the models 
as we have ~ 8.4% of the data diverging and the differences may be of up to 260x.

I will create the new file with correct densities and name it `Final_points_2010_newDensities.csv` and use it 
for repeating Alberto's analysis and comparing the results.

### Loading the tables (run this using the borealBirdsAndForestry.Rproj)
```{r load_tables}
corrDens <- data.table::fread(file.path(getwd(), "inputs", "Habitat_Association_by_jurisdiction(bamddb_Apr19-2012).csv"))
Final_table <- data.table::fread(file.path(getwd(), "inputs", "Final_points_2010.csv"))
```

### Fixing the lookout of LCC PROV BCR for original dataset

First, we need to concatenate the 3 columns to match Alberto's dataset as it is. This way we will be able to identify the 
values that need updating.

```{r concatenate_info}
corrDens$LCC_PROV_B <- paste0(corrDens$LCC, corrDens$PROV, corrDens$BCR)
```

Now we have to subset only the info needed so we can reshape the table and update Alberto's:
```{r subset_data}
spOfInterest <- c("BBWA", "BLPW","BOCH",
                  "BRCR", "BTNW", "CAWA",
                  "CMWA","CONW", "OVEN", 
                  "PISI", "RBNU", "SWTH",
                  "TEWA", "WETA", "YRWA")
density <- corrDens[,.(SPECIES, D, LCC_PROV_B)] %>%
  .[SPECIES %in% spOfInterest]

densityWide <- dcast(density, LCC_PROV_B ~ SPECIES, value.var = "D")
```

At last, we just need to adjust the column names to match the used data.table (this way all scripts still work) merge the two data.tables. 
I will delete the wrong rows first from the original data.table so we won't get it messed up: 
```{r deleting_wrong}
names(densityWide)[2:ncol(densityWide)] <- paste0("BCR_", names(densityWide[2:ncol(densityWide)]))
Final_table_reduced <- Final_table[, which(grepl("BCR_", colnames(Final_table))) := NULL]
```

Now we just eed to merge and calculate the log values:
```{r merge_logs}
Final_table_corrected <- merge(Final_table_reduced, densityWide, by = "LCC_PROV_B")
BCR_cols <- names(Final_table_corrected)[grepl("BCR_", colnames(Final_table_corrected))]
Log_cols <- paste0("LOG_", BCR_cols)
Final_table_corrected_log <- Final_table_corrected[ , (Log_cols) := lapply(X = .SD, FUN = function(x) log(x)), .SDcols = BCR_cols]
```

As a few species don't present abundance in some locations, log values become negative. This is a problem because we can see that these are not the original values. 
Therefore, I will go to the original source (SQL server). Will update then all my work accordingly.

